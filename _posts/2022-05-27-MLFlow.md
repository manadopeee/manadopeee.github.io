---
layout: post
title:  "Machine Learning 흐름"
author: kei
categories: [ 머신러닝, 기초 ]
<!-- image: assets/images/17.jpg -->
beforetoc: "Markdown editor is a very powerful thing. In this article I'm going to show you what you can actually do with it, some tricks and tips while editing your post."
toc: true
---
## Data Preprocessing
> 데이터전처리

## Activation Function
> input과 weight(초기값은 random)의 곱이 활성화 함수를 통해 어떤 임계값이 넘는 값이 들어오면 의미있는 값으로 판단하고 다음 레이어에 값을 제공\
> input과 output의 값을 모두 알고 있다면 weight를 찾아내는 것이 가능\
> 비선형 함수

## Loss Function
> 순전파(forward propagation) 통해 나온 예측값(prediction)을 실제값(label)과 손실 함수를 통해 비교

## Back Propagation
> Loss값이 최소로 되는 방향(오차가 감소)으로 weight를 계산\
> 전체 오차(Loss Function의 output)의 미분값에 learning rate를 곱한 후 기존의 가중치(순전파에서 나온 weight)에서 빼준다\
> activationFunction(input x w)을 출력값(Loss Function의 output)으로 미분\
> output layer에서 input layer 방향으로 실행

## Optimizer
> Loss 값이 최소(기울기가 0)로 나오기 위해 역전파로 계산을 하는데 그러기 위해선 역전파에서 weight를 미분해야한다\
> 가중치(w)의 그래디언트(미분값)가 최소로 되는 지점이 손실 함수의 최소값(지점)이라고 가정\
> 여기서 어떻게 미분을 할 것인가를 정하는 것이 옵티마이저

<figure>
   <a href="https://velog.io/@thwjd639/Backpropagation-%EC%97%AD%EC%A0%84%ED%8C%8C-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98">
   <img src="logo.png" style="max-width: 200px;" alt="Backpropagation 역전파 알고리즘" />
   </a>
<!--    <figcaption>Backpropagation 역전파 알고리즘</figcaption> -->
</figure>
<figure>
   <a href="https://velog.io/@thwjd639/Backpropagation-%EC%97%AD%EC%A0%84%ED%8C%8C-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98">
   <img src="logo.png" style="max-width: 200px;" alt="Jekyll logo" />
   </a>
   <figcaption>Backpropagation 역전파 알고리즘</figcaption>
</figure>
